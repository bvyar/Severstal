{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Модель сегментации Keras"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np, pandas as pd, os\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt, time\nimport random\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Изменяю структуру трейн датафрейма так, чтобы для каждого класса дефекта был отдельный столбец с RLE кодировкой\n\nimages = os.listdir('../input/severstal-steel-defect-detection/train_images')\ntrain = pd.read_csv('../input/severstal-steel-defect-detection/train.csv')\n\ntmp = pd.DataFrame()\ntmp['ImageId_ClassId'] = [images[i] + '_' + str(j) for i in range(len(images)) for j in range(1, 4 + 1)]\ntrain['ImageId_ClassId'] = train['ImageId'] + '_' + train['ClassId'].astype(str)\ntrain = tmp.merge(train, on = ['ImageId_ClassId'], how = 'left')\ntrain['ImageId'] = train['ImageId_ClassId'].map(lambda x: x.split('.')[0]+'.jpg')\n\ntrain2 = pd.DataFrame({'ImageId':train['ImageId'][::4]})\ntrain2['e1'] = train['EncodedPixels'][::4].values\ntrain2['e2'] = train['EncodedPixels'][1::4].values\ntrain2['e3'] = train['EncodedPixels'][2::4].values\ntrain2['e4'] = train['EncodedPixels'][3::4].values\ntrain2.reset_index(inplace = True, drop = True)\ntrain2.fillna('',inplace=True) # заменяю NaN   \n\ntrain = train2.drop_duplicates()\ntrain.head()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"         ImageId e1 e2                                                 e3 e4\n0  74c8a2d5a.jpg                                                            \n1  0d617d477.jpg        109771 7 110014 20 110257 33 110500 46 110743 ...   \n2  66e6c8a78.jpg                                                            \n3  d2670190d.jpg        198674 2 198928 5 199182 8 199435 12 199689 15...   \n4  2e4fefc28.jpg        9239 1 9494 2 9749 3 10005 4 10260 5 10515 6 1...   ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>e1</th>\n      <th>e2</th>\n      <th>e3</th>\n      <th>e4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74c8a2d5a.jpg</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0d617d477.jpg</td>\n      <td></td>\n      <td></td>\n      <td>109771 7 110014 20 110257 33 110500 46 110743 ...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>66e6c8a78.jpg</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>d2670190d.jpg</td>\n      <td></td>\n      <td></td>\n      <td>198674 2 198928 5 199182 8 199435 12 199689 15...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2e4fefc28.jpg</td>\n      <td></td>\n      <td></td>\n      <td>9239 1 9494 2 9749 3 10005 4 10260 5 10515 6 1...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверка\ntrain.shape","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"(12568, 5)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Проверка\ntrain['ImageId'].value_counts()","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"88ab9068d.jpg    1\n5c876d114.jpg    1\n1ada6a7ac.jpg    1\n17e6e4b30.jpg    1\n1a9c38991.jpg    1\n                ..\n34ee04d85.jpg    1\ne39c0bbac.jpg    1\n25bc3a693.jpg    1\n90524c39b.jpg    1\nd85d973bd.jpg    1\nName: ImageId, Length: 12568, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle2mask(rle, imgshape):\n    height = imgshape[0]\n    width = imgshape[1]\n    mask = np.zeros(width * height).astype(np.uint8)\n    rle_array = np.asarray([int(x) for x in rle.split()]) # RLE string to array\n    start_pixels = rle_array[0::2]\n    run_lengths = rle_array[1::2]\n\n    for i in range(len(start_pixels)):\n        mask[start_pixels[i]:start_pixels[i] + run_lengths[i]] = 1 # одномерный массив, состоящий из 256 * 1600 = 409600 элементов\n    mask = mask.reshape(width, height) # 1600 строк, 256 столбцов\n    return mask.T # 256 строк, 1600 столбцов","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n# Класс, который будет использоваться для подачи данных в режиме реального времени в модель Keras.\n\nclass DataGenerator(keras.utils.Sequence):\n    def __init__(self, df, batch_size = 10, subset = \"train\", shuffle = False, preprocess = None):\n        super().__init__()\n        self.df = df\n        self.shuffle = shuffle\n        self.subset = subset\n        self.batch_size = batch_size\n        self.preprocess = preprocess\n\n        \n        if (self.subset == \"train\") or (self.subset == \"val\"):\n            self.data_path = '../input/severstal-steel-defect-detection/train_images/'\n        elif self.subset == \"test\":\n            self.data_path = '../input/severstal-steel-defect-detection/test_images/'\n        self.on_epoch_end()\n\n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size)) # возвращает количество батчей за эпоху\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.df)) # возвращает одномерный массив с равномерно разнесенными значениями внутри заданного интервала\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes) # перемешивает входной датасет df каждую эпоху\n    \n    def augment(self, images, masks):\n        data_gen_args = dict(horizontal_flip = True, vertical_flip = True)\n        image_datagen = ImageDataGenerator(**data_gen_args)\n        mask_datagen = ImageDataGenerator(**data_gen_args)\n        seed = random.randint(1, 1000)\n        #image_datagen.fit(images, augment=False, rounds=1, seed=seed)\n        #mask_datagen.fit(masks, augment=False, rounds=1, seed=seed)\n        images_aug = image_datagen.flow(images, seed=seed, batch_size = self.batch_size)[0]\n        masks_aug = mask_datagen.flow(masks, seed=seed, batch_size = self.batch_size)[0]\n        return images_aug, masks_aug\n    \n    def augment1(self, img, mask):\n        rand = random.randint(1, 1000)\n        if(rand > 900): return cv2.flip(img, 0), cv2.flip(mask, 0) #отражает изображение по вертикали\n        if(rand < 100): return cv2.flip(img, 1), cv2.flip(mask, 1) #отражает изображение по горизонтали\n        else: return img, mask\n    \n    def __getitem__(self, index): \n        images = np.empty((self.batch_size, 256, 1600, 3), dtype=np.float32) # массив, состоящий из batch_size изображений (256x1600x3)\n        masks = np.empty((self.batch_size, 256, 1600, 4), dtype=np.int8) # массив, состоящий из batch_size изображений с масками\n        indexes = self.indexes[index * self.batch_size:(index+1) * self.batch_size]\n        \n        for i, img_id in enumerate(self.df['ImageId'].iloc[indexes]):\n            img = cv2.imread(self.data_path + img_id) # цветовым пространством по умолчанию в OpenCV является BGR\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # чтобы исправить это, используется cvtColor(image, flag) и рассмотренный выше флаг\n            images[i,] = img.astype(np.float32) / 255.\n            if (self.subset == \"train\") or (self.subset == \"val\"): \n                for j in range(4):\n                    masks[i,:,:,j] = rle2mask(self.df['e' + str(j+1)].iloc[indexes[i]], img.shape) # 4 канала, нулевой канал - дефект первого типа, третий канал - дефект четвертого типа\n            if self.subset == \"train\":\n                images[i,], masks[i,] = self.augment1(images[i,], masks[i,])\n        if self.subset == 'train':\n            #images, masks = self.augment(images, masks)\n            return images, masks\n        if self.subset == 'val':\n            return images, masks\n        else: return images # если test","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Модель\nВ качестве модели использовалась архитекстура U-Net с энкодером ResNet34, веса которого были предобучены на ImageNet-e, взято с https://github.com/qubvel/segmentation_models Документация https://segmentation-models.readthedocs.io/en/latest/tutorial.html Модель решала задачу многоклассовой сегментации, то есть одновременно определяла – есть ли на изображении дефект и если есть, то выводила его расположение и класс. Модель тренировалась на полных изображениях 1600x256, без изменения размера. Обучение длилось 60 эпох на видеокарте Tesla P100, это заняло около 12 часов. Первые 40 эпох скорость обучения (learning rate) была равна 1e-3, последние 20 эпох скорость обучена была снижена до 1e-4.\n"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"! pip install segmentation-models","execution_count":7,"outputs":[{"output_type":"stream","text":"Collecting segmentation-models\n  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\nCollecting efficientnet==1.0.0\n  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\nCollecting image-classifiers==1.0.0\n  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 3.5 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet==1.0.0->segmentation-models) (0.16.2)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.18.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation-models) (2.10.0)\nRequirement already satisfied: scipy>=0.19.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.4.1)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (3.2.1)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.4)\nRequirement already satisfied: pillow>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (7.2.0)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.0)\nRequirement already satisfied: PyWavelets>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models) (1.1.1)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->segmentation-models) (1.14.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (0.10.0)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.8.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (2.4.7)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models) (1.2.0)\nRequirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models) (4.4.2)\nInstalling collected packages: keras-applications, efficientnet, image-classifiers, segmentation-models\nSuccessfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation-models-1.0.1\n","name":"stdout"}]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# https://github.com/CyberZHG/keras-radam/blob/master/keras_radam/optimizer_v2.py\n# Дайс метрика качества\n\ndef dice_coef(y_true, y_pred, smooth = 1, THRESHOLD = 0.45):\n    tf.to_float = lambda x: tf.cast(x, tf.float32)\n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    y_pred_f = tf.to_float(y_pred_f > THRESHOLD)\n    intersection = K.sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth) # smooth необходимо, чтобы не возникало деление на ноль","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_distance_loss(y_true, y_pred, smooth = 1):\n    \"\"\"\n    Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n            = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n    \n    The jaccard distance loss is usefull for unbalanced datasets. This has been\n    shifted so it converges on 0 and is smoothed to avoid exploding or disapearing\n    gradient.\n    \n    Ref: https://en.wikipedia.org/wiki/Jaccard_index\n    \n    @url: https://gist.github.com/wassname/f1452b748efcbeb4cb9b1d059dce6f96\n    @author: wassname\n    \"\"\"\n    #tf.to_float = lambda x: tf.cast(x, tf.float32)\n    #y_pred = tf.to_float(y_pred > 0.45)\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n    return (1 - jac) * smooth","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Dice_Coef(y_true, y_pred, smooth = 1):\n    \n    y_true_f = K.flatten(y_true)\n    y_pred_f = K.flatten(y_pred)\n    \n    intersection = K.sum(y_true_f * y_pred_f)\n    \n    return (2*intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n\ndef Dice_Loss(y_true, y_pred):\n    return 1.0 - Dice_Coef(y_true, y_pred)\n\ndef bce_dice_loss(y_true, y_pred):\n    return keras.losses.binary_crossentropy(y_true, y_pred) + Dice_Loss(y_true, y_pred)\n\ndef wbce_dice_loss(y_true, y_pred):\n    return weighted_bce()(y_true, y_pred) + Dice_Loss(y_true, y_pred)\n\ndef weighted_bce(weight = 0.6):\n    \n    def convert_2_logits(y_pred):\n        y_pred = tf.clip_by_value(y_pred, K.epsilon(), 1 - K.epsilon())\n        return tf.math.log(y_pred / (1-y_pred))\n    \n    def weighted_binary_crossentropy(y_true, y_pred):\n        y_pred = convert_2_logits(y_pred)\n        loss = tf.nn.weighted_cross_entropy_with_logits(logits = y_pred, labels = y_true, pos_weight = weight)\n        return loss\n    \n    return weighted_binary_crossentropy","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Взято с https://github.com/CyberZHG/keras-radam/blob/master/keras_radam/optimizer_v2.py\n\nfrom tensorflow.python.keras.optimizer_v2.optimizer_v2 import OptimizerV2\nfrom tensorflow.python import ops, math_ops, state_ops, control_flow_ops\nfrom tensorflow.python.keras import backend as K\n\n__all__ = ['RAdam']\n\n\nclass RAdam(OptimizerV2):\n    \"\"\"RAdam optimizer.\n    According to the paper\n    [On The Variance Of The Adaptive Learning Rate And Beyond](https://arxiv.org/pdf/1908.03265v1.pdf).\n    \"\"\"\n\n    def __init__(self,\n                 learning_rate=0.001,\n                 beta_1=0.9,\n                 beta_2=0.999,\n                 epsilon=1e-7,\n                 weight_decay=0.,\n                 amsgrad=False,\n                 total_steps=0,\n                 warmup_proportion=0.1,\n                 min_lr=0.,\n                 name='RAdam',\n                 **kwargs):\n        r\"\"\"Construct a new Adam optimizer.\n        Args:\n            learning_rate: A Tensor or a floating point value.    The learning rate.\n            beta_1: A float value or a constant float tensor. The exponential decay\n                rate for the 1st moment estimates.\n            beta_2: A float value or a constant float tensor. The exponential decay\n                rate for the 2nd moment estimates.\n            epsilon: A small constant for numerical stability. This epsilon is\n                \"epsilon hat\" in the Kingma and Ba paper (in the formula just before\n                Section 2.1), not the epsilon in Algorithm 1 of the paper.\n            weight_decay: A floating point value. Weight decay for each param.\n            amsgrad: boolean. Whether to apply AMSGrad variant of this algorithm from\n                the paper \"On the Convergence of Adam and beyond\".\n            total_steps: An integer. Total number of training steps.\n                Enable warmup by setting a positive value.\n            warmup_proportion: A floating point value. The proportion of increasing steps.\n            min_lr: A floating point value. Minimum learning rate after warmup.\n            name: Optional name for the operations created when applying gradients.\n                Defaults to \"Adam\".    @compatibility(eager) When eager execution is\n                enabled, `learning_rate`, `beta_1`, `beta_2`, and `epsilon` can each be\n                a callable that takes no arguments and returns the actual value to use.\n                This can be useful for changing these values across different\n                invocations of optimizer functions. @end_compatibility\n            **kwargs: keyword arguments. Allowed to be {`clipnorm`, `clipvalue`, `lr`,\n                `decay`}. `clipnorm` is clip gradients by norm; `clipvalue` is clip\n                gradients by value, `decay` is included for backward compatibility to\n                allow time inverse decay of learning rate. `lr` is included for backward\n                compatibility, recommended to use `learning_rate` instead.\n        \"\"\"\n\n        super(RAdam, self).__init__(name, **kwargs)\n        self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))\n        self._set_hyper('beta_1', beta_1)\n        self._set_hyper('beta_2', beta_2)\n        self._set_hyper('decay', self._initial_decay)\n        self._set_hyper('weight_decay', weight_decay)\n        self._set_hyper('total_steps', float(total_steps))\n        self._set_hyper('warmup_proportion', warmup_proportion)\n        self._set_hyper('min_lr', min_lr)\n        self.epsilon = epsilon or K.epsilon()\n        self.amsgrad = amsgrad\n        self._initial_weight_decay = weight_decay\n        self._initial_total_steps = total_steps\n\n    def _create_slots(self, var_list):\n        for var in var_list:\n            self.add_slot(var, 'm')\n        for var in var_list:\n            self.add_slot(var, 'v')\n        if self.amsgrad:\n            for var in var_list:\n                self.add_slot(var, 'vhat')\n\n    def set_weights(self, weights):\n        params = self.weights\n        num_vars = int((len(params) - 1) / 2)\n        if len(weights) == 3 * num_vars + 1:\n            weights = weights[:len(params)]\n        super(RAdam, self).set_weights(weights)\n\n    def _resource_apply_dense(self, grad, var):\n        var_dtype = var.dtype.base_dtype\n        lr_t = self._decayed_lr(var_dtype)\n        m = self.get_slot(var, 'm')\n        v = self.get_slot(var, 'v')\n        beta_1_t = self._get_hyper('beta_1', var_dtype)\n        beta_2_t = self._get_hyper('beta_2', var_dtype)\n        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n        beta_1_power = math_ops.pow(beta_1_t, local_step)\n        beta_2_power = math_ops.pow(beta_2_t, local_step)\n\n        if self._initial_total_steps > 0:\n            total_steps = self._get_hyper('total_steps', var_dtype)\n            warmup_steps = total_steps * self._get_hyper('warmup_proportion', var_dtype)\n            min_lr = self._get_hyper('min_lr', var_dtype)\n            decay_steps = K.maximum(total_steps - warmup_steps, 1)\n            decay_rate = (min_lr - lr_t) / decay_steps\n            lr_t = tf.where(\n                local_step <= warmup_steps,\n                lr_t * (local_step / warmup_steps),\n                lr_t + decay_rate * K.minimum(local_step - warmup_steps, decay_steps),\n            )\n\n        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n\n        m_t = state_ops.assign(m,\n                               beta_1_t * m + (1.0 - beta_1_t) * grad,\n                               use_locking=self._use_locking)\n        m_corr_t = m_t / (1.0 - beta_1_power)\n\n        v_t = state_ops.assign(v,\n                               beta_2_t * v + (1.0 - beta_2_t) * math_ops.square(grad),\n                               use_locking=self._use_locking)\n        if self.amsgrad:\n            vhat = self.get_slot(var, 'vhat')\n            vhat_t = state_ops.assign(vhat,\n                                      math_ops.maximum(vhat, v_t),\n                                      use_locking=self._use_locking)\n            v_corr_t = math_ops.sqrt(vhat_t / (1.0 - beta_2_power))\n        else:\n            vhat_t = None\n            v_corr_t = math_ops.sqrt(v_t / (1.0 - beta_2_power))\n\n        r_t = math_ops.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n                            (sma_t - 2.0) / (sma_inf - 2.0) *\n                            sma_inf / sma_t)\n\n        var_t = tf.where(sma_t >= 5.0, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t)\n\n        if self._initial_weight_decay > 0.0:\n            var_t += self._get_hyper('weight_decay', var_dtype) * var\n\n        var_update = state_ops.assign_sub(var,\n                                          lr_t * var_t,\n                                          use_locking=self._use_locking)\n\n        updates = [var_update, m_t, v_t]\n        if self.amsgrad:\n            updates.append(vhat_t)\n        return control_flow_ops.group(*updates)\n\n    def _resource_apply_sparse(self, grad, var, indices):\n        var_dtype = var.dtype.base_dtype\n        lr_t = self._decayed_lr(var_dtype)\n        beta_1_t = self._get_hyper('beta_1', var_dtype)\n        beta_2_t = self._get_hyper('beta_2', var_dtype)\n        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n        beta_1_power = math_ops.pow(beta_1_t, local_step)\n        beta_2_power = math_ops.pow(beta_2_t, local_step)\n\n        if self._initial_total_steps > 0:\n            total_steps = self._get_hyper('total_steps', var_dtype)\n            warmup_steps = total_steps * self._get_hyper('warmup_proportion', var_dtype)\n            min_lr = self._get_hyper('min_lr', var_dtype)\n            decay_steps = K.maximum(total_steps - warmup_steps, 1)\n            decay_rate = (min_lr - lr_t) / decay_steps\n            lr_t = tf.where(\n                local_step <= warmup_steps,\n                lr_t * (local_step / warmup_steps),\n                lr_t + decay_rate * K.minimum(local_step - warmup_steps, decay_steps),\n            )\n\n        sma_inf = 2.0 / (1.0 - beta_2_t) - 1.0\n        sma_t = sma_inf - 2.0 * local_step * beta_2_power / (1.0 - beta_2_power)\n\n        m = self.get_slot(var, 'm')\n        m_scaled_g_values = grad * (1 - beta_1_t)\n        m_t = state_ops.assign(m, m * beta_1_t, use_locking=self._use_locking)\n        with ops.control_dependencies([m_t]):\n            m_t = self._resource_scatter_add(m, indices, m_scaled_g_values)\n        m_corr_t = m_t / (1.0 - beta_1_power)\n\n        v = self.get_slot(var, 'v')\n        v_scaled_g_values = (grad * grad) * (1 - beta_2_t)\n        v_t = state_ops.assign(v, v * beta_2_t, use_locking=self._use_locking)\n        with ops.control_dependencies([v_t]):\n            v_t = self._resource_scatter_add(v, indices, v_scaled_g_values)\n\n        if self.amsgrad:\n            vhat = self.get_slot(var, 'vhat')\n            vhat_t = state_ops.assign(vhat,\n                                      math_ops.maximum(vhat, v_t),\n                                      use_locking=self._use_locking)\n            v_corr_t = math_ops.sqrt(vhat_t / (1.0 - beta_2_power))\n        else:\n            vhat_t = None\n            v_corr_t = math_ops.sqrt(v_t / (1.0 - beta_2_power))\n\n        r_t = math_ops.sqrt((sma_t - 4.0) / (sma_inf - 4.0) *\n                            (sma_t - 2.0) / (sma_inf - 2.0) *\n                            sma_inf / sma_t)\n\n        var_t = tf.where(sma_t >= 5.0, r_t * m_corr_t / (v_corr_t + epsilon_t), m_corr_t)\n\n        if self._initial_weight_decay > 0.0:\n            var_t += self._get_hyper('weight_decay', var_dtype) * var\n\n        var_update = self._resource_scatter_add(var, indices, tf.gather(-lr_t * var_t, indices))\n\n        updates = [var_update, m_t, v_t]\n        if self.amsgrad:\n            updates.append(vhat_t)\n        return control_flow_ops.group(*updates)\n\n    def get_config(self):\n        config = super(RAdam, self).get_config()\n        config.update({\n            'learning_rate': self._serialize_hyperparameter('learning_rate'),\n            'beta_1': self._serialize_hyperparameter('beta_1'),\n            'beta_2': self._serialize_hyperparameter('beta_2'),\n            'decay': self._serialize_hyperparameter('decay'),\n            'weight_decay': self._serialize_hyperparameter('weight_decay'),\n            'epsilon': self.epsilon,\n            'amsgrad': self.amsgrad,\n            'total_steps': self._serialize_hyperparameter('total_steps'),\n            'warmup_proportion': self._serialize_hyperparameter('warmup_proportion'),\n            'min_lr': self._serialize_hyperparameter('min_lr'),\n        })\n        return config","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = ModelCheckpoint(\"256_resnet34.h5\", monitor = 'val_dice_coef',\n                             verbose = 1,save_best_only = True, mode = 'max') # сохраняет лучшую модель по Дайс метрике на валидации\ncallbacks_list = [checkpoint]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"use_load_model = True","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if use_load_model == True:\n    model = load_model('../input/pre-model8/256_resnet34 0.9018.h5', custom_objects = {'RAdam': RAdam, 'dice_coef': dice_coef, 'jaccard_distance_loss': jaccard_distance_loss})\n    opt = RAdam(lr = 1e-4, min_lr = 1e-7)\n    model.compile(optimizer = opt, loss = wbce_dice_loss, metrics = [dice_coef])\n\n    train_ids, val_ids = train_test_split(range(len(train)), test_size = 0.2, random_state = 42) # разделяю выборку на трейн и валидацию\n    train_batches = DataGenerator(train.iloc[train_ids], shuffle = True)\n    valid_batches = DataGenerator(train.iloc[val_ids], subset = 'val')\n\n    history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = 45, verbose = 1, callbacks = callbacks_list)","execution_count":null,"outputs":[{"output_type":"stream","text":"Epoch 1/45\n1005/1005 [==============================] - ETA: 0s - loss: 0.1432 - dice_coef: 0.8703\nEpoch 00001: val_dice_coef improved from -inf to 0.90799, saving model to 256_resnet34.h5\n1005/1005 [==============================] - 683s 680ms/step - loss: 0.1432 - dice_coef: 0.8703 - val_loss: 0.0997 - val_dice_coef: 0.9080\nEpoch 2/45\n1005/1005 [==============================] - ETA: 0s - loss: 0.1371 - dice_coef: 0.8733\nEpoch 00002: val_dice_coef did not improve from 0.90799\n1005/1005 [==============================] - 672s 669ms/step - loss: 0.1371 - dice_coef: 0.8733 - val_loss: 0.0989 - val_dice_coef: 0.9079\nEpoch 3/45\n1005/1005 [==============================] - ETA: 0s - loss: 0.1353 - dice_coef: 0.8737\nEpoch 00003: val_dice_coef did not improve from 0.90799\n1005/1005 [==============================] - 671s 668ms/step - loss: 0.1353 - dice_coef: 0.8737 - val_loss: 0.0997 - val_dice_coef: 0.9071\nEpoch 4/45\n1005/1005 [==============================] - ETA: 0s - loss: 0.1336 - dice_coef: 0.8753\nEpoch 00004: val_dice_coef did not improve from 0.90799\n1005/1005 [==============================] - 669s 665ms/step - loss: 0.1336 - dice_coef: 0.8753 - val_loss: 0.1032 - val_dice_coef: 0.9037\nEpoch 5/45\n1005/1005 [==============================] - ETA: 0s - loss: 0.1361 - dice_coef: 0.8728\nEpoch 00005: val_dice_coef did not improve from 0.90799\n1005/1005 [==============================] - 669s 666ms/step - loss: 0.1361 - dice_coef: 0.8728 - val_loss: 0.1001 - val_dice_coef: 0.9066\nEpoch 6/45\n1005/1005 [==============================] - ETA: 0s - loss: 0.1293 - dice_coef: 0.8792\nEpoch 00006: val_dice_coef did not improve from 0.90799\n1005/1005 [==============================] - 668s 665ms/step - loss: 0.1293 - dice_coef: 0.8792 - val_loss: 0.1010 - val_dice_coef: 0.9057\nEpoch 7/45\n 223/1005 [=====>........................] - ETA: 7:56 - loss: 0.1284 - dice_coef: 0.8796","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import segmentation_models as sm\n#from segmentation_models import Unet\n\nif use_load_model == False:\n    opt = RAdam(lr = 1e-3, min_lr = 1e-7)\n    model = Unet('resnet34', input_shape = (256, 1600, 3), classes = 4, activation = 'sigmoid')\n    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = [dice_coef])\n\n    train_ids, val_ids = train_test_split(range(len(train)), test_size = 0.2, random_state = 42) # разделяю выборку на трейн и валидацию\n    train_batches = DataGenerator(train.iloc[train_ids], shuffle = True)\n    valid_batches = DataGenerator(train.iloc[val_ids], subset = 'val')\n\n    history = model.fit_generator(train_batches, validation_data = valid_batches, epochs = 10, verbose = 1, callbacks = callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 10\nran_ids = random.choices(val_ids, k = batch_size)\nval_set = train.iloc[ran_ids] # 10 случайных картинок из валидации\n\nvalid_batches = DataGenerator(val_set, subset = 'val')\npreds = model.predict_generator(valid_batches, verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Графическое сравнение предсказаний модели с метками из валидационной выборки\n\nTHRESHOLD = 0.45\ncolors = [(249, 192, 12), (0, 185, 241), (114, 0, 218), (249,50,12)]\n\nfor i, batch in enumerate(valid_batches):\n    for k in range(batch_size):\n        fig, ax = plt.subplots(1, 2, figsize=(23, 23))\n        img = batch[0][k,]\n        img = np.float32(img) * 255.\n        img = (img).astype(np.uint8)\n        img1 = img.copy()\n        has_defect = False\n        extra = ' имеет дефект'\n        extra_pred = ' наличие дефекта'\n        for j in range(4):\n            mask = batch[1][k,:,:,j].astype(np.uint8)\n            if np.sum(mask) != 0: \n                has_defect = True\n                extra += ' ' + str(j+1)\n            contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n            cv2.drawContours(img, contours, -1, colors[j], 2, cv2.LINE_AA)\n        ax[0].imshow(img)\n        if(has_defect == False): extra = '  не имеет дефектов '\n        ax[0].set_title('Валидация ' + str(train['ImageId'].iloc[ran_ids[k]]) + extra, fontsize=18)\n        for j in range(4):\n            mask = preds[k,:,:,j]\n            mask[mask >= THRESHOLD] = 1\n            mask[mask < THRESHOLD] = 0\n            mask = mask.astype(np.uint8)\n            if np.sum(mask) != 0: \n                extra_pred += ' ' + str(j+1)\n            contours, _ = cv2.findContours(mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n            cv2.drawContours(img1, contours, -1, colors[j], 2, cv2.LINE_AA)\n        ax[1].imshow(img1)\n        if(has_defect == False): extra_pred = ' отсутствие дефектов '\n        ax[1].set_title('Модель предсказывает' + extra_pred, fontsize=18)\n        fig.subplots_adjust(wspace = 0.05, hspace = 0.01)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# График коэффициента Дайса на трейне и тесте по эпохам\nplt.figure(figsize=(15,5))\nplt.plot(range(history.epoch[-1]+1),history.history['val_dice_coef'],label='val_dice_coef')\nplt.plot(range(history.epoch[-1]+1),history.history['dice_coef'],label='trn_dice_coef')\nplt.title('Training Accuracy'); plt.xlabel('Epoch'); plt.ylabel('Dice_coef');plt.legend(); \nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}